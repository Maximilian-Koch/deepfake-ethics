<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Deepfake Detective - About</title>
</head>
<body>
    <div class="background-overlay"></div>
    <header>
        <h1>Deepfake Detective</h1>
        <p class="tagline">About & Ethical Framework</p>
    </header>

    <main id="about-content">
        <section>
            <h2>Overview</h2>
            <p>This quiz was developed as part of an assignment for my degree in Computational Social Science, University of Amsterdam.
               Its purpose is to show the various ethical considerations and dilemmas that arise from emerging deepfake technology,
               in an interactive experience. </p>
            <p>Created by: <a href="https://www.linkedin.com/in/maximilian-jw-koch/">Maximilian Koch</a></p>
        </section>

        <section>
            <h2>The Deepfake Dilemma</h2>
            <p>With deepfake technology, realistic multimedia content of existing people can be created. This technology allows for various types of applications, which gives rise to a wicked ethical dilemma: <br> <b>Should we value free expression and innovation or should we prioritise truth, safety and dignity?</b> <br>
                The dilemma here lies less so in the different ethical frameworks of the same case, but more so in creating decision points of what is considered an (un)ethical application.
                <br>The examples shown in the game all depict a different angle of the dilemma - by distributing deepfakes inciting voter suppression, Biden’s dignity was violated and the general public deceived. The potential of deepfakes to manipulate public opinion was considered very or somewhat concerning by 91.8% of participants in a UK study (Sippy et al., 2024). While here preference utilitarianism and deontology lead to a definite conclusion, as described in the game notes, with exhibit 2 it becomes more complicated. <br>Besides using deepfake for autodubbing movies, the entertainment industry could profit from updating film footage using deepfakes instead of potentially expensive reshooting and bringing back long-dead actors (Westerlund, 2019). Additionally, some other applications include resurrecting characters/actors, background replacement and automated visual effects, which can lead to a rapid iteration of different ideas and savings in budget and time (Mittal et al., 2024).
                <br>The same autodubbing technology of exhibit 2 has also been applied in the third exhibit, with David Beckham’s voice speaking in nine languages, only one of them being his actual voice. In education, this technology can be used to break down language barriers and can improve the quality and accessibility of education world-wide, although currently there is a low intention by stakeholders to integrate deepfakes into education (Roe et al., 2025).
                <br>The fourth exhibit showcases two different types of deepfakes at once: Firstly, it is used to discredit the depicted persons (Donald Trump and Elon Musk), and secondly, it touches upon the topic of deepfake (revenge) pornography. While the discreditation goes against values of dignity, the evaluation of the collected data of this tool shows that several participants viewed this application as ethical, due to their opposing political stance to both persons. This tendency to support deepfakes that discredit the opposing side has also been shown in deepfakes involving the Russo-Ukrainian war (Twomey et al., 2023). Regarding the latter, revenge pornography was not explicitly included in the exhibits due to its nature. However, this does not make it less of an issue. It violates deontological dignity, transparency and any values relevant to ethics of care. These concerns also show in a UK survey where 89.6% of participants were very or somewhat concerned with deepfakes increasing misogyny and other gender-related violence (Sippy et al., 2024).
                <br>In the final exhibit, a personal assistant makes a phone call. In the example it is unclear whether this violates transparency in a deontological framework, however from an ethics of care lens, tools like these can improve the accessibility for individuals with social anxiety, speaking difficulties, or again, language barriers. In a comparable case, deepfake technology can also be used to help people with Alzheimer's interact with a younger face they may remember. (Westerlund, 2019).
                <br>Due to the complexity of the topic, only a few of the (potential) applications were included - other usages can be, but are not limited to, simplified advertising for businesses as less people are needed, trying clothes online using a tool, fraud  and blackmailing (Westerlund, 2019).
                </p>
        </section>

        <section>
            <h2>Target Audience, Relevance and Outlook</h2>
            <p>The target audience of this tool is the general public, with a focus on social media users. Deep fakes have become part of our daily lives, whether it is in our Instagram feed, used in the news on TV, making its way into the newspaper or even changing the discourse on topics in person.<br> However, in a study 16.5% were not confident about being able to spot deepfakes, and most people (66.1%) were unsure about their ability to do so (Sippy et al., 2024).<br> Users being able to detect (unethical use of) deepfakes is crucial in maintaining epistemic security. While AI deepfake detection methods exist, they can only work short term due to a reinforcing cycle of improved deepfakes and improved detection algorithms (Vincent, 2019). However, training the user awareness actually improves the user detection abilities (Ahmed et al., 2021). This aligns with qualitative argumentations that the answer to the (anticipated) loss in epistemic security lies not in developing technological solutions, but creating norms for techno-social practices that go against the post-truth narrative (Habgood-Coote, 2023).
            </p>
        </section>

        <section>
            <h2>Ethical Framework Summary</h2>
            <p>For this tool, I mostly used preference utilitarianism and deontology to analyse the ethical considerations. However, also other ethical frameworks can be used. Below is a summary of the position of different frameworks on deepfakes:
            </p>
            <ul>
                <li><strong>Preference Utilitarianism:</strong><br>In preference utilitarianism an action is considered morally right if it maximises the satisfaction of the preferences of all those affected. It focuses on outcomes.<br>
                    In a majority of the deepfake applications this framework would judge negatively. Malicious deepfakes go against the preferences of the depicted individuals and the public. While the creator and some viewers might have a preference satisfied, this is usually outweighed by the intensity of violated preferences. Even seemingly harmless deepfakes could undermine a general preference for authenticity.
                </li>
                <li><strong>Deontology:</strong><br>Deontology determines the rightfulness of an action based on whether it adheres to moral rules or duties, regardless of the consequences. The key principle is the Categorical Imperative, which states that one shall only act on principles one could will to be universal laws.<br>
                    Especially deceptive deepfakes would be condemned in this framework. Deepfakes often disrespect the autonomy of humans and treat the person as means to deceive, harm or entertain. When transparency and consent are given, deontological views would rather view these as morally right.
                </li>
                <li><strong>Ethics of Care:</strong><br>In Ethics of Care, empathy, compassion, and responsiveness to the needs of others are prioritised, especially towards vulnerable groups. Context is valued over abstract principles.<br>
                    Harmful deepfakes would clearly be condemned in this framework, as trust is violated, the victims are under emotional distress, and relationships can be damaged. However, accessibility for vulnerable groups, as demonstrated in the last exhibit, can also be improved through deepfakes, which ethics of care supports.
                </li>
                <li><strong>Justice as Fairness:</strong><br>Justice as fairness proposes that principles of justice should ensure equal basic liberties for all and always consider the least advantaged in decision making.<br>
                    Deepfakes would be seen as unjust, especially when it harms vulnerable groups. From behind the veil of ignorance, individuals would likely want strong protections against deepfakes, as anyone could potentially become a victim, as also such technology can easily harm less advantaged groups.
                </li>
                <li><strong>Feminist Ethics:</strong><br>This diverse set of frameworks critiques traditional ethics for ignoring or devaluing women’s experiences.<br>
                    In the context of deepfakes, feminist ethics would be highly critical, as they are disproportionately weaponised against women, specifically deepfake (revenge) pornography. This also shows in the observation that especially women are concerned about and affected by deepfake pornography (Sippy et al., 2024).
                </li>
                <li><strong>Virtue Ethics (Aristotle):</strong><br> Ethics states that morality is about cultivating virtues, avoiding vices to achieve eudaimonia, by thinking about the kind person one should become.<br>
                    Depending on the deepfakes, this framework would judge differently. Creating malicious deepfakes demonstrates vices of the user, such as dishonesty and malice. A virtuous person could still however create deepfakes that express virtues, such as justice (e.g. political satire) or compassion (e.g. accessibility).
                </li>
                <li><strong>Universal Ethical Egoism:</strong><br>This framework asserts that individuals ought to act in their own self-interest. Morality is then based purely on what benefits the individual.<br>
                    Deepfakes could often be seen as ethical in this framework, as they can lead to personal gain, e.g. preferred political outcome, financial outcome or perceived self-justice. This framework could easily be used by creators of deepfakes to justify their actions.
                </li>
            </ul>
        </section>

        <section>
            <h2>Design Theory and A/B testing</h2>
            <p>Cognitive Load Theory was used as design guidance (Sweller, 2010): The intrinsic load of detecting deep fakes can not be reduced well, as only choosing 'obvious' examples would ignore the inherent complexity. Thus I focused on reducing the intrinsic load given by the ethical dilemmas. The extraneous load was partially reduced, as I used a minimal layout. However, to test color psychology’s assumption of the effect of designs on human behavior, I used two different designs - red/black and blue/white. A harsh, low-contrast red/black design results in a higher extraneous load than a clean blue/white design. This high cognitive load can impair complex reading and prime users into specific directions.
                <br>I limited the amount of ethical frameworks used for the exhibits to limit the intrinsic cognitive load, always using preference utilitarianism and deontology, and only adding ethics of care and justice of fairness where I thought their addition was invaluable. However, on this page I added further considerations of other frameworks, for interested users.
                <br>The scores were stored in a database and can be used for further analysis. The following queries have been developed:
                <br> - What is the average impact of ethical considerations on the users judgement, depending on the design theme?
                <br> - How does the score before and after considerations differ based on whether the user guessed fake/real, depending on the design theme?
                <br> - How much does the initial and overall score change across themes?
                <br> - What is the influence of the theme on how often users guess real/fake for the exhibits?
                <br>Currently, only a small number of people have used the tool, thus there is no representative, usable data yet.                
            </p>
        </section>

        <section>
            <h2>Further Reading & Sources</h2>
            <strong>Further Reading</strong>
            <ul>
                <li><a href='https://www.masterborn.com/blog/Introduction-to-Deepfake-Technology-with-Examples'>
                    An introduction to deepfakes, its history and technology</a>
                </li>
                <li><a href='https://newsroom.ibm.com/Blog-Heres-What-Policymakers-Can-Do-About-Deepfakes'>A summary of what policies can help the effects</a>
                </li>
                <li><a href='https://www.nytimes.com/2023/01/22/business/media/deepfake-regulation-difficulty.html'>The difficulty of regulating deepfakes</a>
                </li>
            </ul>
            <strong>Sources</strong>
            <ul>
                <li>Ahmed, M. F. B., Miah, M. S. U., Bhowmik, A., & Sulaiman, J. B. (2021, July). Awareness to Deepfake: A resistance mechanism to Deepfake. In 2021 International Congress of Advanced Technology and Engineering (ICOTEN) (pp. 1-5). IEEE.
                </li>
                <li>Habgood-Coote, J. Deepfakes and the epistemic apocalypse. Synthese 201, 103 (2023).</li>
                <li>Mittal, S., Joshi, M., Vats, P., Upadhayay, G. M., Vats, S. K., & Kumar, S. (2024, March). Virtual Illusions: Unleashing Deepfake Expertise for Enhanced Visual Effects in Film Production. In 2024 11th International Conference on Reliability, Infocom Technologies and Optimization (Trends and Future Directions)(ICRITO) (pp. 1-6). IEEE.
                </li>
                <li>Roe, J., Perkins, M., Somoray, K., Miller, D., & Furze, L. (2025). To Deepfake or Not to Deepfake: Higher Education Stakeholders' Perceptions and Intentions towards Synthetic Media.
                </li>
                <li>Sippy, T., Enock, F.E., Bright, J., & Margetts, H.Z. (2024). Behind the Deepfake: 8% Create; 90% Concerned. Surveying public exposure to and perceptions of deepfakes in the UK.
                </li>
                <li>Sweller, J. (2010). Element interactivity and intrinsic, extraneous, and germane cognitive load. Educational psychology review, 22, 123-138.
                </li>
                <li>Twomey J, Ching D, Aylett MP, Quayle M, Linehan C, et al. (2023) Do deepfake videos undermine our epistemic trust? A thematic analysis of tweets that discuss deepfakes in the Russian invasion of Ukraine. PLOS ONE 18(10): e0291668.
                </li>
                <li>Vincent, J. (2019, Jun 27). Deepfake detection algorithms will never be enough. The Verge. theverge.com
                </li>
                <li>Westerlund, M. (2019). The emergence of deepfake technology: A review. Technology innovation management review, 9(11).
                </li>
            </ul>
            <strong>Multimedia Sources</strong>
            <ul>
                <li>Background photo for dark mode: https://unsplash.com/photos/man-wearing-black-knit-cap-pSYxtX9ekbI</li>
                <li>Exhibit 1 - Audio clip: https://edition.cnn.com/2024/01/22/politics/fake-joe-biden-robocall/index.html, https://soundcloud.com/user-429524614/fake-joe-biden-robocall-nh</li>
                <li>Exhibit 2 - Trailer: https://youtu.be/VH4AnOAVS1c</li>
                <li>Exhibit 3 - 9 languages : Beckham: https://www.youtube.com/watch?v=QiiSAvKJIHo</li>
                <li>Exhibit 4 - Tweet: https://x.com/krassenstein/status/1894047931738558515</li>
                <li>Exhibit 5  - Google Assistant: https://www.youtube.com/watch?v=JvbHu_bVa_g</li>
            </ul>

        </section>

         <section class="call-to-action">
             <a href="index.html" class="cta-button">Back to Homepage</a>
             <a href="game.html" class="cta-button">Play the Game</a>
         </section>
    </main>

    <footer>
        <p>&copy; Deepfake Detective - CSSci - Maximilian Koch | <a href="about.html">About & Sources</a></p>
    </footer>

    <script src="/static/script.js"></script> </body>
</html>